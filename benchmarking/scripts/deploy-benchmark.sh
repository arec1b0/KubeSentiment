#!/bin/bash
# MLOps Sentiment Analysis - Automated Benchmarking Deployment Script
# ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ñ€Ð°Ð·Ð²ÐµÑ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð·Ð°Ð¿ÑƒÑÐº Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð² Ð½Ð° Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð°Ñ… Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²

set -e

# Ð¦Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
CONFIG_FILE="${PROJECT_ROOT}/configs/benchmark-config.yaml"
RESULTS_DIR="${PROJECT_ROOT}/results"
NAMESPACE="mlops-benchmark"

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
check_dependencies() {
    log_info "ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹..."
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ kubectl
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Kubernetes CLI."
        exit 1
    fi
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ helm
    if ! command -v helm &> /dev/null; then
        log_error "helm Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Helm."
        exit 1
    fi
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ python
    if ! command -v python3 &> /dev/null; then
        log_error "python3 Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½."
        exit 1
    fi
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñƒ
    if ! kubectl cluster-info &> /dev/null; then
        log_error "ÐÐµÑ‚ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº Kubernetes ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñƒ."
        exit 1
    fi
    
    log_success "Ð’ÑÐµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ñ‹"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ namespace
create_namespace() {
    log_info "Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ namespace: $NAMESPACE"
    
    if kubectl get namespace "$NAMESPACE" &> /dev/null; then
        log_warning "Namespace $NAMESPACE ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚"
    else
        kubectl create namespace "$NAMESPACE"
        log_success "Namespace $NAMESPACE ÑÐ¾Ð·Ð´Ð°Ð½"
    fi
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ labels Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
    kubectl label namespace "$NAMESPACE" monitoring=enabled --overwrite
    kubectl label namespace "$NAMESPACE" benchmark=true --overwrite
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Python Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
install_python_deps() {
    log_info "Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Python Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹..."
    
    cd "$PROJECT_ROOT"
    
    if [ -f "requirements.txt" ]; then
        pip3 install -r requirements.txt
        log_success "Python Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹"
    else
        log_warning "requirements.txt Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, ÑÐ¾Ð·Ð´Ð°ÐµÐ¼..."
        cat > requirements.txt << EOF
asyncio
aiohttp
pyyaml
numpy
pandas
matplotlib
seaborn
psutil
kubernetes
pynvml
prometheus-client
EOF
        pip3 install -r requirements.txt
        log_success "Python Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹"
    fi
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð·Ð²ÐµÑ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° CPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐµ
deploy_cpu_instance() {
    local instance_type=$1
    log_info "Ð Ð°Ð·Ð²ÐµÑ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ðµ CPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ°: $instance_type"
    
    # ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÐ¼ deployment Ñ„Ð°Ð¹Ð»
    local deployment_file="/tmp/cpu-deployment-${instance_type}.yaml"
    cp "${PROJECT_ROOT}/deployments/cpu-deployment.yaml" "$deployment_file"
    
    # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚Ð¸Ð¿ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ° Ð² deployment
    sed -i "s/t3.medium/$instance_type/g" "$deployment_file"
    sed -i "s/mlops-sentiment-cpu/mlops-sentiment-cpu-${instance_type}/g" "$deployment_file"
    
    # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ deployment
    kubectl apply -f "$deployment_file" -n "$NAMESPACE"
    
    # Ð–Ð´ÐµÐ¼ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð´Ð°
    log_info "ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð´Ð°..."
    kubectl wait --for=condition=ready pod -l app=mlops-sentiment,instance-type=cpu -n "$NAMESPACE" --timeout=300s
    
    log_success "CPU Ð¸Ð½ÑÑ‚Ð°Ð½Ñ $instance_type Ñ€Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð·Ð²ÐµÑ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° GPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐµ
deploy_gpu_instance() {
    local instance_type=$1
    local gpu_type=$2
    log_info "Ð Ð°Ð·Ð²ÐµÑ€Ñ‚Ñ‹Ð²Ð°Ð½Ð¸Ðµ GPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ°: $instance_type ($gpu_type)"
    
    # ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÐ¼ deployment Ñ„Ð°Ð¹Ð»
    local deployment_file="/tmp/gpu-deployment-${instance_type}.yaml"
    cp "${PROJECT_ROOT}/deployments/gpu-deployment.yaml" "$deployment_file"
    
    # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚Ð¸Ð¿ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ° Ð¸ GPU Ð² deployment
    sed -i "s/nvidia-tesla-t4/nvidia-${gpu_type,,}/g" "$deployment_file"
    sed -i "s/mlops-sentiment-gpu/mlops-sentiment-gpu-${instance_type}/g" "$deployment_file"
    
    # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ deployment
    kubectl apply -f "$deployment_file" -n "$NAMESPACE"
    
    # Ð–Ð´ÐµÐ¼ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð´Ð°
    log_info "ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ GPU Ð¿Ð¾Ð´Ð°..."
    kubectl wait --for=condition=ready pod -l app=mlops-sentiment,instance-type=gpu -n "$NAMESPACE" --timeout=600s
    
    log_success "GPU Ð¸Ð½ÑÑ‚Ð°Ð½Ñ $instance_type Ñ€Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°
run_benchmark() {
    local instance_name=$1
    local instance_type=$2
    local service_name=$3
    
    log_info "Ð—Ð°Ð¿ÑƒÑÐº Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ° Ð´Ð»Ñ $instance_name"
    
    # Port-forward Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº ÑÐµÑ€Ð²Ð¸ÑÑƒ
    local local_port=$((8080 + RANDOM % 1000))
    kubectl port-forward "svc/$service_name" "$local_port:80" -n "$NAMESPACE" &
    local port_forward_pid=$!
    
    # Ð–Ð´ÐµÐ¼ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
    sleep 10
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð² Ð² Ñ„Ð¾Ð½Ðµ
    log_info "Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²..."
    python3 "${SCRIPT_DIR}/resource-monitor.py" \
        --namespace "$NAMESPACE" \
        --duration 360 \
        --output "${RESULTS_DIR}/resource_metrics_${instance_name}.json" &
    local monitor_pid=$!
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
    log_info "Ð—Ð°Ð¿ÑƒÑÐº Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ..."
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹
    local users_array=(1 5 10 20 50 100)
    
    for users in "${users_array[@]}"; do
        log_info "Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ $users Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼Ð¸..."
        
        python3 "${SCRIPT_DIR}/load-test.py" \
            --config "$CONFIG_FILE" \
            --instance-type "$instance_name" \
            --endpoint "http://localhost:$local_port/predict" \
            --users "$users" \
            --duration 60 \
            --output "${RESULTS_DIR}/benchmark_${instance_name}_${users}users.json" \
            --report-dir "${RESULTS_DIR}/reports"
        
        # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð¿Ð°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚ÐµÑÑ‚Ð°Ð¼Ð¸
        sleep 30
    done
    
    # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³
    kill $monitor_pid 2>/dev/null || true
    
    # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ port-forward
    kill $port_forward_pid 2>/dev/null || true
    
    log_success "Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº Ð´Ð»Ñ $instance_name Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
consolidate_results() {
    log_info "ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð²..."
    
    cd "$RESULTS_DIR"
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ²Ð¾Ð´Ð½Ñ‹Ð¹ JSON Ñ„Ð°Ð¹Ð»
    echo "[]" > consolidated_results.json
    
    # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    for result_file in benchmark_*.json; do
        if [ -f "$result_file" ]; then
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² ÑÐ²Ð¾Ð´Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
            jq '. += [input]' consolidated_results.json "$result_file" > temp.json && mv temp.json consolidated_results.json
        fi
    done
    
    log_success "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ñ‹ Ð² consolidated_results.json"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸
generate_cost_report() {
    log_info "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸..."
    
    python3 "${SCRIPT_DIR}/cost-calculator.py" \
        --config "$CONFIG_FILE" \
        --results "${RESULTS_DIR}/consolidated_results.json" \
        --predictions 1000 \
        --output "${RESULTS_DIR}/cost_analysis.json" \
        --report-dir "${RESULTS_DIR}/cost_reports"
    
    log_success "ÐžÑ‚Ñ‡ÐµÑ‚ Ð¾ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
cleanup() {
    log_info "ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²..."
    
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²ÑÐµ deployments Ð² namespace
    kubectl delete deployments --all -n "$NAMESPACE" 2>/dev/null || true
    kubectl delete services --all -n "$NAMESPACE" 2>/dev/null || true
    kubectl delete hpa --all -n "$NAMESPACE" 2>/dev/null || true
    kubectl delete pdb --all -n "$NAMESPACE" 2>/dev/null || true
    
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
    rm -f /tmp/cpu-deployment-*.yaml
    rm -f /tmp/gpu-deployment-*.yaml
    
    log_success "Ð ÐµÑÑƒÑ€ÑÑ‹ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ñ‹"
}

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
generate_final_report() {
    log_info "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°..."
    
    local report_file="${RESULTS_DIR}/benchmark_final_report.md"
    
    cat > "$report_file" << EOF
# ðŸ“Š MLOps Sentiment Analysis - Benchmark Report

**Ð”Ð°Ñ‚Ð°:** $(date)
**Namespace:** $NAMESPACE

## ðŸŽ¯ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°

### ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÑ‹:
EOF
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ñ‚ÐµÑÑ‚Ðµ
    for result_file in "${RESULTS_DIR}"/benchmark_*.json; do
        if [ -f "$result_file" ]; then
            local instance_name=$(jq -r '.instance_type' "$result_file")
            local rps=$(jq -r '.requests_per_second' "$result_file")
            local latency=$(jq -r '.avg_latency' "$result_file")
            local users=$(jq -r '.concurrent_users' "$result_file")
            
            echo "- **$instance_name** ($users users): ${rps} RPS, ${latency}ms latency" >> "$report_file"
        fi
    done
    
    cat >> "$report_file" << EOF

## ðŸ“ˆ Ð¤Ð°Ð¹Ð»Ñ‹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²:
- Ð¡Ð²Ð¾Ð´Ð½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹: \`consolidated_results.json\`
- ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸: \`cost_analysis.json\`
- Ð“Ñ€Ð°Ñ„Ð¸ÐºÐ¸ Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ: \`reports/\` Ð¸ \`cost_reports/\`
- ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²: \`resource_metrics_*.json\`

## ðŸš€ Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ ÑˆÐ°Ð³Ð¸:
1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² \`cost_reports/\`
2. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ð°ÑˆÐ¸Ñ… Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹
3. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ production deployment Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸

EOF
    
    log_success "Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ ÑÐ¾Ð·Ð´Ð°Ð½: $report_file"
}

# ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ
main() {
    log_info "ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸Ð½Ð³Ð° MLOps Sentiment Analysis"
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
    mkdir -p "$RESULTS_DIR"/{reports,cost_reports}
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
    check_dependencies
    
    # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Python Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
    install_python_deps
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ namespace
    create_namespace
    
    # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²
    log_info "Ð§Ñ‚ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²..."
    
    # CPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÑ‹
    local cpu_instances=($(yq eval '.instances.cpu[].name' "$CONFIG_FILE"))
    log_info "ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ CPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²: ${#cpu_instances[@]}"
    
    # GPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÑ‹  
    local gpu_instances=($(yq eval '.instances.gpu[].name' "$CONFIG_FILE"))
    log_info "ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ GPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²: ${#gpu_instances[@]}"
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸ Ð´Ð»Ñ CPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²
    for instance in "${cpu_instances[@]}"; do
        local instance_type=$(yq eval ".instances.cpu[] | select(.name == \"$instance\") | .type" "$CONFIG_FILE")
        
        deploy_cpu_instance "$instance_type"
        run_benchmark "$instance" "cpu" "mlops-sentiment-cpu-${instance_type}-svc"
        
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ deployment Ð¿ÐµÑ€ÐµÐ´ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ Ñ‚ÐµÑÑ‚Ð¾Ð¼
        kubectl delete deployment "mlops-sentiment-cpu-${instance_type}" -n "$NAMESPACE" || true
        sleep 30
    done
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸ Ð´Ð»Ñ GPU Ð¸Ð½ÑÑ‚Ð°Ð½ÑÐ¾Ð²
    for instance in "${gpu_instances[@]}"; do
        local instance_type=$(yq eval ".instances.gpu[] | select(.name == \"$instance\") | .type" "$CONFIG_FILE")
        local gpu_type=$(yq eval ".instances.gpu[] | select(.name == \"$instance\") | .gpu" "$CONFIG_FILE")
        
        deploy_gpu_instance "$instance_type" "$gpu_type"
        run_benchmark "$instance" "gpu" "mlops-sentiment-gpu-${instance_type}-svc"
        
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ deployment Ð¿ÐµÑ€ÐµÐ´ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ Ñ‚ÐµÑÑ‚Ð¾Ð¼
        kubectl delete deployment "mlops-sentiment-gpu-${instance_type}" -n "$NAMESPACE" || true
        sleep 30
    done
    
    # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    consolidate_results
    
    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð¾ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸
    generate_cost_report
    
    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚
    generate_final_report
    
    # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ñ€ÐµÑÑƒÑ€ÑÑ‹
    cleanup
    
    log_success "ðŸŽ‰ Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸Ð½Ð³ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½! Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ Ð²: $RESULTS_DIR"
    log_info "ðŸ“Š ÐžÑ‚ÐºÑ€Ð¾Ð¹Ñ‚Ðµ $RESULTS_DIR/benchmark_final_report.md Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"
}

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð¹ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸
trap cleanup EXIT INT TERM

# ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸
while [[ $# -gt 0 ]]; do
    case $1 in
        --config)
            CONFIG_FILE="$2"
            shift 2
            ;;
        --namespace)
            NAMESPACE="$2"
            shift 2
            ;;
        --results-dir)
            RESULTS_DIR="$2"
            shift 2
            ;;
        --cleanup-only)
            cleanup
            exit 0
            ;;
        --help)
            echo "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ: $0 [OPTIONS]"
            echo "ÐžÐ¿Ñ†Ð¸Ð¸:"
            echo "  --config FILE         ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: configs/benchmark-config.yaml)"
            echo "  --namespace NAME      Kubernetes namespace (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: mlops-benchmark)"
            echo "  --results-dir DIR     Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð»Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: results)"
            echo "  --cleanup-only        Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ñ€ÐµÑÑƒÑ€ÑÑ‹ Ð¸ Ð²Ñ‹Ð¹Ñ‚Ð¸"
            echo "  --help               ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ñƒ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ"
            exit 0
            ;;
        *)
            log_error "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾Ð¿Ñ†Ð¸Ñ: $1"
            exit 1
            ;;
    esac
done

# Ð—Ð°Ð¿ÑƒÑÐº Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸
main
