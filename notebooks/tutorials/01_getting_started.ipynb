{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ KubeSentiment: Getting Started\n",
    "\n",
    "Welcome to **KubeSentiment** - a production-ready sentiment analysis microservice! This notebook will guide you through the basics of using this MLOps sentiment analysis service.\n",
    "\n",
    "## üìã What is KubeSentiment?\n",
    "\n",
    "KubeSentiment is a comprehensive MLOps solution that provides:\n",
    "- **Real-time sentiment analysis** using DistilBERT\n",
    "- **Production-ready API** built with FastAPI\n",
    "- **Kubernetes deployment** with auto-scaling\n",
    "- **Comprehensive monitoring** with Prometheus & Grafana\n",
    "- **Performance benchmarking** tools\n",
    "- **ONNX optimization** for improved performance\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand the KubeSentiment architecture\n",
    "2. Learn how to interact with the API\n",
    "3. Perform basic sentiment analysis\n",
    "4. Understand the response format\n",
    "5. Explore error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Architecture Overview\n",
    "\n",
    "KubeSentiment follows a microservice architecture:\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[Client] --> B[API Gateway]\n",
    "    B --> C[Sentiment Service]\n",
    "    C --> D[Hugging Face Model]\n",
    "    C --> E[Prediction Cache]\n",
    "    \n",
    "    F[Prometheus] --> G[Metrics]\n",
    "    H[Grafana] --> G\n",
    "    I[AlertManager] --> J[Notifications]\n",
    "```\n",
    "\n",
    "### Key Components:\n",
    "- **FastAPI Backend**: High-performance async API\n",
    "- **DistilBERT Model**: Pre-trained sentiment analysis model\n",
    "- **LRU Cache**: Performance optimization for repeated predictions\n",
    "- **Prometheus Metrics**: Real-time monitoring\n",
    "- **Kubernetes**: Container orchestration and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Dependencies\n",
    "\n",
    "First, let's install the required dependencies and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for this notebook\n",
    "# Note: This cell might take a few minutes to run\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Version Check\n",
    "Let's check the versions of the installed libraries to ensure our environment is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List installed packages to ensure reproducibility\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Connecting to the API\n",
    "\n",
    "KubeSentiment provides a REST API. Let's first check if the service is running and explore the available endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "API_BASE_URL = \"http://localhost:8000\"  # Change this if your service runs on a different port\n",
    "\n",
    "def check_service_health(base_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Check if the sentiment analysis service is healthy.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/health\", timeout=10)\n",
    "        return {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"healthy\": response.status_code == 200,\n",
    "            \"data\": response.json() if response.status_code == 200 else None,\n",
    "            \"error\": None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status_code\": None,\n",
    "            \"healthy\": False,\n",
    "            \"data\": None,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Check service health\n",
    "health_status = check_service_health(API_BASE_URL)\n",
    "\n",
    "if health_status[\"healthy\"]:\n",
    "    print(\"‚úÖ Service is healthy!\")\n",
    "    print(f\"üìä Status: {health_status['data']}\")\n",
    "else:\n",
    "    print(\"‚ùå Service is not available\")\n",
    "    print(f\"üîç Error: {health_status['error']}\")\n",
    "    print(\"\\nüí° Make sure the service is running:\")\n",
    "    print(\"   docker run -d -p 8000:8000 sentiment-service:latest\")\n",
    "    print(\"   # or\")\n",
    "    print(\"   python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Information\n",
    "\n",
    "Let's explore what model is being used and its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(base_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get information about the loaded model.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/model-info\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Get model information\n",
    "if health_status[\"healthy\"]:\n",
    "    model_info = get_model_info(API_BASE_URL)\n",
    "    \n",
    "    if \"error\" not in model_info:\n",
    "        print(\"ü§ñ Model Information:\")\n",
    "        print(f\"üìù Model Name: {model_info.get('model_name', 'N/A')}\")\n",
    "        print(f\"‚úÖ Loaded: {model_info.get('is_loaded', False)}\")\n",
    "        print(f\"üöÄ Ready: {model_info.get('is_ready', False)}\")\n",
    "        print(f\"üíæ Cache Size: {model_info.get('cache_stats', {}).get('cache_size', 0)}\")\n",
    "        print(f\"üîß PyTorch Version: {model_info.get('torch_version', 'N/A')}\")\n",
    "        print(f\"üñ•Ô∏è CUDA Available: {model_info.get('cuda_available', False)}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error getting model info: {model_info['error']}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping model info check - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Sentiment Analysis\n",
    "\n",
    "Now let's perform some sentiment analysis! The API accepts text and returns sentiment predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(base_url: str, text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze sentiment of the given text.\"\"\"\n",
    "    try:\n",
    "        payload = {\"text\": text}\n",
    "        response = requests.post(\n",
    "            f\"{base_url}/predict\", \n",
    "            json=payload, \n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\n",
    "                \"error\": f\"HTTP {response.status_code}\", \n",
    "                \"details\": response.text,\n",
    "                \"text\": text\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"text\": text}\n",
    "\n",
    "# Test cases with different sentiments\n",
    "test_texts = [\n",
    "    \"I absolutely love this product! It's amazing and works perfectly.\",\n",
    "    \"This is terrible. I'm very disappointed with the quality.\",\n",
    "    \"The service was okay, nothing special but it worked.\",\n",
    "    \"Outstanding customer support and excellent features!\",\n",
    "    \"Worst experience ever. Complete waste of money.\",\n",
    "    \"It's decent, does what it needs to do without issues.\"\n",
    "]\n",
    "\n",
    "print(\"üéØ Sentiment Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if health_status[\"healthy\"]:\n",
    "    results = []\n",
    "    for text in test_texts:\n",
    "        result = analyze_sentiment(API_BASE_URL, text)\n",
    "        \n",
    "        if \"error\" not in result:\n",
    "            print(f\"üìù Text: {text[:50]}...\")\n",
    "            print(f\"üòä Sentiment: {result['label']}\")\n",
    "            print(f\"üìä Confidence: {result['score']:.3f}\")\n",
    "            print(f\"‚ö° Inference Time: {result['inference_time_ms']:.2f}ms\")\n",
    "            print(f\"üìè Text Length: {result['text_length']} chars\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"label\": result[\"label\"],\n",
    "                \"score\": result[\"score\"],\n",
    "                \"inference_time_ms\": result[\"inference_time_ms\"],\n",
    "                \"text_length\": result[\"text_length\"]\n",
    "            })\n",
    "        else:\n",
    "            print(f\"‚ùå Error analyzing: {text[:30]}...\")\n",
    "            print(f\"   Error: {result['error']}\")\n",
    "            print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping sentiment analysis - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Analyzing Results\n",
    "\n",
    "Let's create some visualizations to understand our sentiment analysis results better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from results\n",
    "if 'results' in locals() and results:\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Display results table\n",
    "    print(\"üìä Sentiment Analysis Summary:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Sentiment Analysis Results', fontsize=16)\n",
    "    \n",
    "    # 1. Sentiment distribution\n",
    "    sentiment_counts = df['label'].value_counts()\n",
    "    axes[0, 0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Sentiment Distribution')\n",
    "    \n",
    "    # 2. Confidence scores\n",
    "    colors = ['green' if label == 'POSITIVE' else 'red' if label == 'NEGATIVE' else 'blue' \n",
    "              for label in df['label']]\n",
    "    axes[0, 1].bar(range(len(df)), df['score'], color=colors)\n",
    "    axes[0, 1].set_title('Confidence Scores')\n",
    "    axes[0, 1].set_xlabel('Sample')\n",
    "    axes[0, 1].set_ylabel('Confidence')\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # 3. Inference time distribution\n",
    "    axes[1, 0].hist(df['inference_time_ms'], bins=10, alpha=0.7, color='skyblue')\n",
    "    axes[1, 0].set_title('Inference Time Distribution')\n",
    "    axes[1, 0].set_xlabel('Time (ms)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 4. Text length vs confidence\n",
    "    scatter_colors = ['green' if label == 'POSITIVE' else 'red' if label == 'NEGATIVE' else 'blue' \n",
    "                      for label in df['label']]\n",
    "    axes[1, 1].scatter(df['text_length'], df['score'], c=scatter_colors, alpha=0.6)\n",
    "    axes[1, 1].set_title('Text Length vs Confidence')\n",
    "    axes[1, 1].set_xlabel('Text Length')\n",
    "    axes[1, 1].set_ylabel('Confidence Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nüìà Summary Statistics:\")\n",
    "    print(f\"üìä Total predictions: {len(df)}\")\n",
    "    print(f\"üòä Positive sentiments: {len(df[df['label'] == 'POSITIVE'])}\")\n",
    "    print(f\"üò¢ Negative sentiments: {len(df[df['label'] == 'NEGATIVE'])}\")\n",
    "    print(f\"üòê Neutral sentiments: {len(df[df['label'] == 'NEUTRAL'])}\")\n",
    "    print(f\"‚ö° Average inference time: {df['inference_time_ms'].mean():.2f}ms\")\n",
    "    print(f\"üìè Average text length: {df['text_length'].mean():.0f} characters\")\n",
    "    print(f\"üéØ Average confidence: {df['score'].mean():.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è No results to analyze - service not available or no predictions made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö® Error Handling\n",
    "\n",
    "Let's explore how the API handles various error conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error scenarios\n",
    "error_test_cases = [\n",
    "    {\"text\": \"\", \"description\": \"Empty text\"},\n",
    "    {\"text\": \"   \", \"description\": \"Whitespace only\"},\n",
    "    {\"text\": \"a\" * 10000, \"description\": \"Text too long\"},\n",
    "    {\"text\": \"This is normal text.\", \"description\": \"Valid text (should work)\"}\n",
    "]\n",
    "\n",
    "print(\"üö® Error Handling Test Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if health_status[\"healthy\"]:\n",
    "    for test_case in error_test_cases:\n",
    "        result = analyze_sentiment(API_BASE_URL, test_case[\"text\"])\n",
    "        \n",
    "        print(f\"üß™ Test: {test_case['description']}\")\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"   ‚ùå Expected error: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Success: {result['label']} (confidence: {result['score']:.3f})\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping error handling tests - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Performance Metrics\n",
    "\n",
    "Let's check the service's performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(base_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get service performance metrics.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/metrics-json\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Get performance metrics\n",
    "if health_status[\"healthy\"]:\n",
    "    metrics = get_metrics(API_BASE_URL)\n",
    "    \n",
    "    if \"error\" not in metrics:\n",
    "        print(\"üìä Performance Metrics:\")\n",
    "        print(f\"üîß PyTorch Version: {metrics.get('torch_version', 'N/A')}\")\n",
    "        print(f\"üñ•Ô∏è CUDA Available: {metrics.get('cuda_available', 'N/A')}\")\n",
    "        print(f\"üíæ Memory Allocated: {metrics.get('cuda_memory_allocated_mb', 0)} MB\")\n",
    "        print(f\"üìà Memory Reserved: {metrics.get('cuda_memory_reserved_mb', 0)} MB\")\n",
    "        print(f\"üéÆ CUDA Devices: {metrics.get('cuda_device_count', 0)}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error getting metrics: {metrics['error']}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping metrics check - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Automated Testing\n",
    "\n",
    "We can integrate automated tests directly into our notebooks using `pytest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test file\n",
    "test_code = \"\"\"\n",
    "import requests\n",
    "def test_health_check():\n",
    "    # Health check should be available without auth\n",
    "    response = requests.get('http://localhost:8000/health')\n",
    "    assert response.status_code == 200, f\\\"Expected 200, got {response.status_code}\\\"\n",
    "    assert response.json()[\\\"status\\\"] == \\\"healthy\\\", \\\"Service is not healthy\\\"\n",
    "\"\"\"\n",
    "with open(\"test_api.py\", \"w\") as f:\n",
    "    f.write(test_code)\n",
    "\n",
    "# Run pytest\n",
    "!pytest test_api.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "\n",
    "1. ‚úÖ **Connected to the KubeSentiment API**\n",
    "2. ‚úÖ **Explored the model capabilities**\n",
    "3. ‚úÖ **Performed sentiment analysis**\n",
    "4. ‚úÖ **Analyzed results with visualizations**\n",
    "5. ‚úÖ **Tested error handling**\n",
    "6. ‚úÖ **Checked performance metrics**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you understand the basics, explore these advanced topics:\n",
    "\n",
    "- **[../experiments/02_model_exploration.ipynb](../experiments/02_model_exploration.ipynb)**: Deep dive into the sentiment model\n",
    "- **[../production/03_api_testing.ipynb](../production/03_api_testing.ipynb)**: Comprehensive API testing\n",
    "- **[../production/04_benchmarking_analysis.ipynb](../production/04_benchmarking_analysis.ipynb)**: Performance benchmarking\n",
    "- **[../production/05_monitoring_metrics.ipynb](../production/05_monitoring_metrics.ipynb)**: Advanced monitoring\n",
    "- **[06_development_workflow.ipynb](06_development_workflow.ipynb)**: Development workflows\n",
    "- **[../production/07_deployment_guide.ipynb](../production/07_deployment_guide.ipynb)**: Production deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "- **[API Documentation](http://localhost:8000/docs)**: Interactive Swagger UI\n",
    "- **[Main README](../../README.md)**: Complete project documentation\n",
    "- **[Architecture Guide](../../docs/architecture.md)**: System design overview\n",
    "- **[Benchmarking Guide](../../docs/BENCHMARKING.md)**: Performance testing\n",
    "\n",
    "---\n",
    "\n",
    "**Happy analyzing! üéØ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
