{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Development Workflow: KubeSentiment Development & Testing\n",
    "\n",
    "This notebook explores the development workflow for KubeSentiment, including testing strategies, code quality, CI/CD integration, and best practices for MLOps development.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand the testing pyramid and test coverage\n",
    "2. Learn about code quality tools and automation\n",
    "3. Explore CI/CD pipeline integration\n",
    "4. Understand development best practices\n",
    "5. Learn debugging and troubleshooting techniques\n",
    "6. Master the development workflow from idea to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Dependencies\n",
    "\n",
    "First, let's install the required dependencies and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for this notebook\n",
    "# Note: This cell might take a few minutes to run\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Version Check\n",
    "Let's check the versions of the installed libraries to ensure our environment is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List installed packages to ensure reproducibility\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Testing Pyramid & Strategy\n",
    "\n",
    "### The Testing Pyramid\n",
    "\n",
    "```\n",
    "     /\\\n",
    "    /  \\\n",
    "   /Unit\\\n",
    "  /______\\\n",
    " /Integration\\\n",
    "/____________\\\n",
    "     E2E\n",
    "```\n",
    "\n",
    "### KubeSentiment Testing Strategy\n",
    "\n",
    "- **Unit Tests**: Test individual functions and classes\n",
    "- **Integration Tests**: Test API endpoints and service interactions\n",
    "- **End-to-End Tests**: Test complete user workflows\n",
    "- **Performance Tests**: Load testing and benchmarking\n",
    "- **Security Tests**: Vulnerability scanning and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pytest\n",
    "import coverage\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Define paths\n",
    "PROJECT_ROOT = Path(\"../../\")\n",
    "APP_DIR = PROJECT_ROOT / \"app\"\n",
    "TESTS_DIR = PROJECT_ROOT / \"tests\"\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìÅ Project root: {PROJECT_ROOT.absolute()}\")\n",
    "print(f\"üß™ Tests directory: {TESTS_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Test Coverage Analysis\n",
    "\n",
    "Let's analyze the current test coverage and identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests and analyze coverage\n",
    "def run_test_suite():\n",
    "    \"\"\"Run the complete test suite and collect results.\"\"\"\n",
    "    \n",
    "    print(\"üß™ Running Test Suite...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Change to project root\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "    try:\n",
    "        # Run pytest with coverage\n",
    "        result = subprocess.run([\n",
    "            sys.executable, '-m', 'pytest', \n",
    "            'tests/', \n",
    "            '-v', \n",
    "            '--tb=short',\n",
    "            '--cov=app',\n",
    "            '--cov-report=json',\n",
    "            '--cov-report=term-missing'\n",
    "        ], capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        print(\"üìä Test Results:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"‚ö†Ô∏è Errors/Warnings:\")\n",
    "            print(result.stderr)\n",
    "        \n",
    "        # Check if coverage report was generated\n",
    "        coverage_file = Path(\"coverage.json\")\n",
    "        if coverage_file.exists():\n",
    "            with open(coverage_file, 'r') as f:\n",
    "                coverage_data = json.load(f)\n",
    "            \n",
    "            # Extract summary\n",
    "            totals = coverage_data.get('totals', {})\n",
    "            covered_lines = totals.get('covered_lines', 0)\n",
    "            num_statements = totals.get('num_statements', 1)\n",
    "            coverage_percent = totals.get('percent_covered', 0)\n",
    "            \n",
    "            return {\n",
    "                \"success\": result.returncode == 0,\n",
    "                \"return_code\": result.returncode,\n",
    "                \"stdout\": result.stdout,\n",
    "                \"stderr\": result.stderr,\n",
    "                \"coverage\": {\n",
    "                    \"covered_lines\": covered_lines,\n",
    "                    \"total_lines\": num_statements,\n",
    "                    \"percentage\": coverage_percent\n",
    "                },\n",
    "                \"coverage_data\": coverage_data\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Coverage report not generated\",\n",
    "                \"stdout\": result.stdout,\n",
    "                \"stderr\": result.stderr\n",
    "            }\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return {\"success\": False, \"error\": \"Test execution timed out\"}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "# Run tests if in the correct environment\n",
    "if PROJECT_ROOT.exists() and TESTS_DIR.exists():\n",
    "    test_results = run_test_suite()\n",
    "    \n",
    "    if test_results[\"success\"]:\n",
    "        print(\"‚úÖ Test suite completed successfully!\")\n",
    "        \n",
    "        if \"coverage\" in test_results:\n",
    "            cov = test_results[\"coverage\"]\n",
    "            print(f\"üìä Code Coverage: {cov['percentage']:.1f}%\")\n",
    "            print(f\"   üìù Covered Lines: {cov['covered_lines']}\")\n",
    "            print(f\"   üìè Total Lines: {cov['total_lines']}\")\n",
    "    else:\n",
    "        print(\"‚ùå Test suite failed\")\n",
    "        print(f\"üîç Error: {test_results.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        # Show some output for debugging\n",
    "        stdout = test_results.get('stdout', '')\n",
    "        if stdout:\n",
    "            print(\"\\nüìÑ Test Output (first 500 chars):\")\n",
    "            print(stdout[:500] + \"...\" if len(stdout) > 500 else stdout)\n",
    "\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping test execution - not in project environment\")\n",
    "    print(\"üí° To run tests, execute this notebook from the project root directory\")\n",
    "    \n",
    "    # Create sample test results for demonstration\n",
    "    test_results = {\n",
    "        \"success\": True,\n",
    "        \"coverage\": {\n",
    "            \"covered_lines\": 850,\n",
    "            \"total_lines\": 1200,\n",
    "            \"percentage\": 70.8\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Code Quality Analysis\n",
    "\n",
    "Let's analyze code quality using various linting and formatting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code quality analysis\n",
    "def analyze_code_quality():\n",
    "    \"\"\"Run code quality analysis tools.\"\"\"\n",
    "    \n",
    "    quality_results = {}\n",
    "    \n",
    "    # Change to project root\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "    # List of tools to check\n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"black\",\n",
    "            \"command\": [\"black\", \"--check\", \"--diff\", \"app/\", \"tests/\"],\n",
    "            \"description\": \"Code formatting check\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"isort\",\n",
    "            \"command\": [\"isort\", \"--check-only\", \"--diff\", \"app/\", \"tests/\"],\n",
    "            \"description\": \"Import sorting check\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ruff\",\n",
    "            \"command\": [\"ruff\", \"check\", \"app/\", \"tests/\"],\n",
    "            \"description\": \"Fast Python linter\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"mypy\",\n",
    "            \"command\": [\"mypy\", \"app/\", \"--ignore-missing-imports\"],\n",
    "            \"description\": \"Static type checking\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"flake8\",\n",
    "            \"command\": [\"flake8\", \"app/\", \"tests/\", \"--max-line-length=88\", \"--extend-ignore=E203,W503\"],\n",
    "            \"description\": \"Style guide enforcement\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for tool in tools:\n",
    "        print(f\"üîç Running {tool['name']} - {tool['description']}\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                tool[\"command\"],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            quality_results[tool[\"name\"]] = {\n",
    "                \"success\": result.returncode == 0,\n",
    "                \"return_code\": result.returncode,\n",
    "                \"stdout\": result.stdout,\n",
    "                \"stderr\": result.stderr,\n",
    "                \"description\": tool[\"description\"]\n",
    "            }\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"   ‚úÖ PASSED\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå FAILED (exit code: {result.returncode})\")\n",
    "                \n",
    "                # Show first few lines of output\n",
    "                output = result.stdout + result.stderr\n",
    "                if output:\n",
    "                    lines = output.split('\\n')[:5]\n",
    "                    for line in lines:\n",
    "                        if line.strip():\n",
    "                            print(f\"      {line}\")\n",
    "                    \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ‚ö†Ô∏è {tool['name']} not installed\")\n",
    "            quality_results[tool[\"name\"]] = {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Tool not installed\",\n",
    "                \"description\": tool[\"description\"]\n",
    "            }\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"   ‚è±Ô∏è {tool['name']} timed out\")\n",
    "            quality_results[tool[\"name\"]] = {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Timeout\",\n",
    "                \"description\": tool[\"description\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"   üí• {tool['name']} error: {e}\")\n",
    "            quality_results[tool[\"name\"]] = {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"description\": tool[\"description\"]\n",
    "            }\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return quality_results\n",
    "\n",
    "# Run code quality analysis\n",
    "print(\"üîß Code Quality Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "quality_results = analyze_code_quality()\n",
    "\n",
    "# Summarize results\n",
    "total_tools = len(quality_results)\n",
    "passed_tools = sum(1 for r in quality_results.values() if r.get(\"success\", False))\n",
    "\n",
    "print(f\"üìä Code Quality Summary: {passed_tools}/{total_tools} tools passed\")\n",
    "\n",
    "# Visualize results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "tools = list(quality_results.keys())\n",
    "passed = [1 if r.get(\"success\", False) else 0 for r in quality_results.values()]\n",
    "failed = [1 if not r.get(\"success\", False) else 0 for r in quality_results.values()]\n",
    "\n",
    "bar1 = ax.bar(tools, passed, label='Passed', color='green', alpha=0.7)\n",
    "bar2 = ax.bar(tools, failed, bottom=passed, label='Failed', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_ylabel('Status')\n",
    "ax.set_title('Code Quality Tool Results')\n",
    "ax.set_xticklabels(tools, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, status in zip(bar1, passed):\n",
    "    if status > 0:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height/2, '‚úì', \n",
    "                ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show detailed results for failed tools\n",
    "failed_tools = [name for name, result in quality_results.items() if not result.get(\"success\", False)]\n",
    "if failed_tools:\n",
    "    print(\"\\n‚ùå Failed Tools Details:\")\n",
    "    for tool_name in failed_tools:\n",
    "        result = quality_results[tool_name]\n",
    "        print(f\"\\nüîß {tool_name} ({result.get('description', 'Unknown')}):\")\n",
    "        if 'error' in result:\n",
    "            print(f\"   Error: {result['error']}\")\n",
    "        else:\n",
    "            # Show first few lines of output\n",
    "            output = result.get('stdout', '') + result.get('stderr', '')\n",
    "            lines = output.split('\\n')[:10]\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All code quality checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ CI/CD Pipeline Analysis\n",
    "\n",
    "Let's examine the CI/CD pipeline configuration and understand the automated testing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI/CD pipeline analysis\n",
    "def analyze_ci_cd_pipeline():\n",
    "    \"\"\"Analyze the CI/CD pipeline configuration.\"\"\"\n",
    "    \n",
    "    pipeline_info = {}\n",
    "    \n",
    "    # Analyze GitHub Actions workflow\n",
    "    workflow_file = PROJECT_ROOT / \".github\" / \"workflows\" / \"ci.yml\"\n",
    "    \n",
    "    if workflow_file.exists():\n",
    "        try:\n",
    "            import yaml\n",
    "            with open(workflow_file, 'r') as f:\n",
    "                workflow = yaml.safe_load(f)\n",
    "            \n",
    "            pipeline_info['github_actions'] = {\n",
    "                \"name\": workflow.get('name', 'Unknown'),\n",
    "                \"triggers\": workflow.get('on', {}),\n",
    "                \"jobs\": list(workflow.get('jobs', {}).keys()),\n",
    "                \"python_version\": workflow.get('env', {}).get('PYTHON_VERSION', 'Unknown'),\n",
    "                \"registry\": workflow.get('env', {}).get('REGISTRY', 'Unknown')\n",
    "            }\n",
    "            \n",
    "            # Analyze jobs\n",
    "            jobs_info = []\n",
    "            for job_name, job_config in workflow.get('jobs', {}).items():\n",
    "                steps = job_config.get('steps', [])\n",
    "                jobs_info.append({\n",
    "                    \"name\": job_name,\n",
    "                    \"runs_on\": job_config.get('runs-on', 'Unknown'),\n",
    "                    \"steps_count\": len(steps),\n",
    "                    \"key_steps\": [step.get('name', 'Unknown') for step in steps[:5]]\n",
    "                })\n",
    "            \n",
    "            pipeline_info['jobs_detail'] = jobs_info\n",
    "            \n",
    "        except ImportError:\n",
    "            pipeline_info['github_actions'] = {\"error\": \"PyYAML not available\"}\n",
    "        except Exception as e:\n",
    "            pipeline_info['github_actions'] = {\"error\": str(e)}\n",
    "    else:\n",
    "        pipeline_info['github_actions'] = {\"error\": \"Workflow file not found\"}\n",
    "    \n",
    "    # Check for other CI/CD files\n",
    "    other_files = [\n",
    "        PROJECT_ROOT / \".travis.yml\",\n",
    "        PROJECT_ROOT / \"Jenkinsfile\",\n",
    "        PROJECT_ROOT / \".gitlab-ci.yml\",\n",
    "        PROJECT_ROOT / \"Makefile\"\n",
    "    ]\n",
    "    \n",
    "    pipeline_info['other_ci_files'] = []\n",
    "    for file_path in other_files:\n",
    "        if file_path.exists():\n",
    "            pipeline_info['other_ci_files'].append({\n",
    "                \"file\": file_path.name,\n",
    "                \"exists\": True,\n",
    "                \"size\": file_path.stat().st_size\n",
    "            })\n",
    "    \n",
    "    # Check for Docker-related files\n",
    "    docker_files = [\n",
    "        PROJECT_ROOT / \"Dockerfile\",\n",
    "        PROJECT_ROOT / \"docker-compose.yml\",\n",
    "        PROJECT_ROOT / \".dockerignore\"\n",
    "    ]\n",
    "    \n",
    "    pipeline_info['docker_files'] = []\n",
    "    for file_path in docker_files:\n",
    "        if file_path.exists():\n",
    "            pipeline_info['docker_files'].append({\n",
    "                \"file\": file_path.name,\n",
    "                \"exists\": True,\n",
    "                \"size\": file_path.stat().st_size\n",
    "            })\n",
    "    \n",
    "    return pipeline_info\n",
    "\n",
    "# Analyze CI/CD pipeline\n",
    "print(\"üîÑ CI/CD Pipeline Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "pipeline_info = analyze_ci_cd_pipeline()\n",
    "\n",
    "# Display GitHub Actions info\n",
    "if 'github_actions' in pipeline_info:\n",
    "    ga = pipeline_info['github_actions']\n",
    "    if 'error' not in ga:\n",
    "        print(\"ü§ñ GitHub Actions Workflow:\")\n",
    "        print(f\"   üìù Name: {ga['name']}\")\n",
    "        print(f\"   üêç Python Version: {ga['python_version']}\")\n",
    "        print(f\"   üì¶ Container Registry: {ga['registry']}\")\n",
    "        print(f\"   üîÑ Jobs: {', '.join(ga['jobs'])}\")\n",
    "        \n",
    "        # Triggers\n",
    "        triggers = ga['triggers']\n",
    "        print(f\"   üéØ Triggers:\")\n",
    "        if 'push' in triggers:\n",
    "            push = triggers['push']\n",
    "            if 'branches' in push:\n",
    "                print(f\"      Push to branches: {', '.join(push['branches'])}\")\n",
    "        if 'pull_request' in triggers:\n",
    "            pr = triggers['pull_request']\n",
    "            if 'branches' in pr:\n",
    "                print(f\"      PR to branches: {', '.join(pr['branches'])}\")\n",
    "        \n",
    "        # Job details\n",
    "        if 'jobs_detail' in pipeline_info:\n",
    "            print(f\"\\nüìã Job Details:\")\n",
    "            for job in pipeline_info['jobs_detail']:\n",
    "                print(f\"   üîß {job['name']} ({job['runs_on']}):\")\n",
    "                print(f\"      Steps: {job['steps_count']}\")\n",
    "                print(f\"      Key steps: {', '.join(job['key_steps'][:3])}\")\n",
    "    else:\n",
    "        print(f\"‚ùå GitHub Actions error: {ga['error']}\")\n",
    "\n",
    "# Display other CI/CD files\n",
    "other_files = pipeline_info.get('other_ci_files', [])\n",
    "if other_files:\n",
    "    print(f\"\\nüìÅ Other CI/CD Files:\")\n",
    "    for file_info in other_files:\n",
    "        print(f\"   üìÑ {file_info['file']} ({file_info['size']} bytes)\")\n",
    "\n",
    "# Display Docker files\n",
    "docker_files = pipeline_info.get('docker_files', [])\n",
    "if docker_files:\n",
    "    print(f\"\\nüê≥ Docker Files:\")\n",
    "    for file_info in docker_files:\n",
    "        print(f\"   üì¶ {file_info['file']} ({file_info['size']} bytes)\")\n",
    "\n",
    "# Create pipeline visualization\n",
    "if 'jobs_detail' in pipeline_info:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    jobs = pipeline_info['jobs_detail']\n",
    "    job_names = [job['name'] for job in jobs]\n",
    "    step_counts = [job['steps_count'] for job in jobs]\n",
    "    \n",
    "    bars = ax.bar(job_names, step_counts, color='skyblue', alpha=0.7)\n",
    "    ax.set_ylabel('Number of Steps')\n",
    "    ax.set_title('CI/CD Pipeline Complexity')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, step_counts):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.1, str(count), \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ CI/CD Analysis Complete!\")\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"   ‚Ä¢ Automated testing on multiple branches\")\n",
    "print(\"   ‚Ä¢ Multi-stage pipeline: test ‚Üí build ‚Üí deploy\")\n",
    "print(\"   ‚Ä¢ Security scanning integrated\")\n",
    "print(\"   ‚Ä¢ Multi-environment deployment support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêõ Debugging and Troubleshooting\n",
    "\n",
    "Let's explore common debugging techniques and troubleshooting workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging and troubleshooting utilities\n",
    "def analyze_common_issues():\n",
    "    \"\"\"Analyze common development and deployment issues.\"\"\"\n",
    "    \n",
    "    issues_analysis = {\n",
    "        \"import_errors\": {\n",
    "            \"symptoms\": [\"ModuleNotFoundError\", \"ImportError\", \"No module named\"],\n",
    "            \"causes\": [\"Missing dependencies\", \"Virtual environment not activated\", \"PYTHONPATH issues\"],\n",
    "            \"solutions\": [\n",
    "                \"pip install -r requirements.txt\",\n",
    "                \"source venv/bin/activate (Linux/Mac)\",\n",
    "                \"venv\\\\Scripts\\\\activate (Windows)\",\n",
    "                \"Check PYTHONPATH environment variable\"\n",
    "            ]\n",
    "        },\n",
    "        \"model_loading_failures\": {\n",
    "            \"symptoms\": [\"ModelNotLoadedError\", \"Failed to load model\", \"HuggingFace error\"],\n",
    "            \"causes\": [\"Network connectivity\", \"Invalid model name\", \"Cache directory issues\"],\n",
    "            \"solutions\": [\n",
    "                \"Check internet connection\",\n",
    "                \"Verify model name in settings\",\n",
    "                \"Clear model cache: rm -rf ~/.cache/huggingface\",\n",
    "                \"Set HF_HUB_OFFLINE=1 for offline mode\"\n",
    "            ]\n",
    "        },\n",
    "        \"api_connection_errors\": {\n",
    "            \"symptoms\": [\"Connection refused\", \"Timeout\", \"502 Bad Gateway\"],\n",
    "            \"causes\": [\"Service not running\", \"Wrong port\", \"Network issues\"],\n",
    "            \"solutions\": [\n",
    "                \"Check if service is running: docker ps\",\n",
    "                \"Verify port configuration\",\n",
    "                \"Check service logs: docker logs <container>\",\n",
    "                \"Test connectivity: curl http://localhost:8000/health\"\n",
    "            ]\n",
    "        },\n",
    "        \"performance_issues\": {\n",
    "            \"symptoms\": [\"Slow responses\", \"High latency\", \"Memory errors\"],\n",
    "            \"causes\": [\"Resource constraints\", \"Inefficient code\", \"Cache misses\"],\n",
    "            \"solutions\": [\n",
    "                \"Monitor resource usage\",\n",
    "                \"Profile code performance\",\n",
    "                \"Optimize cache settings\",\n",
    "                \"Consider model optimization (ONNX)\"\n",
    "            ]\n",
    "        },\n",
    "        \"test_failures\": {\n",
    "            \"symptoms\": [\"Test failures\", \"Assertion errors\", \"Import errors in tests\"],\n",
    "            \"causes\": [\"Code changes\", \"Environment differences\", \"Mock setup issues\"],\n",
    "            \"solutions\": [\n",
    "                \"Run tests locally first\",\n",
    "                \"Check test dependencies\",\n",
    "                \"Update test mocks and fixtures\",\n",
    "                \"Review recent code changes\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return issues_analysis\n",
    "\n",
    "# Create troubleshooting guide\n",
    "def create_troubleshooting_workflow():\n",
    "    \"\"\"Create a systematic troubleshooting workflow.\"\"\"\n",
    "    \n",
    "    workflow = {\n",
    "        \"step_1_reproduce\": {\n",
    "            \"title\": \"Reproduce the Issue\",\n",
    "            \"actions\": [\n",
    "                \"Gather error messages and logs\",\n",
    "                \"Note exact steps to reproduce\",\n",
    "                \"Record environment details (OS, Python version, etc.)\",\n",
    "                \"Try to isolate the problem\"\n",
    "            ]\n",
    "        },\n",
    "        \"step_2_check_basics\": {\n",
    "            \"title\": \"Check Basic Functionality\",\n",
    "            \"actions\": [\n",
    "                \"Verify service is running\",\n",
    "                \"Check network connectivity\",\n",
    "                \"Validate configuration\",\n",
    "                \"Test with minimal example\"\n",
    "            ]\n",
    "        },\n",
    "        \"step_3_analyze_logs\": {\n",
    "            \"title\": \"Analyze Logs and Metrics\",\n",
    "            \"actions\": [\n",
    "                \"Check application logs\",\n",
    "                \"Review monitoring dashboards\",\n",
    "                \"Look for error patterns\",\n",
    "                \"Compare with working baseline\"\n",
    "            ]\n",
    "        },\n",
    "        \"step_4_isolate_cause\": {\n",
    "            \"title\": \"Isolate the Root Cause\",\n",
    "            \"actions\": [\n",
    "                \"Use binary search to isolate changes\",\n",
    "                \"Test individual components\",\n",
    "                \"Check recent deployments/changes\",\n",
    "                \"Review configuration differences\"\n",
    "            ]\n",
    "        },\n",
    "        \"step_5_implement_fix\": {\n",
    "            \"title\": \"Implement and Test Fix\",\n",
    "            \"actions\": [\n",
    "                \"Develop minimal fix\",\n",
    "                \"Test fix thoroughly\",\n",
    "                \"Verify no regressions\",\n",
    "                \"Document the solution\"\n",
    "            ]\n",
    "        },\n",
    "        \"step_6_prevent_future\": {\n",
    "            \"title\": \"Prevent Future Issues\",\n",
    "            \"actions\": [\n",
    "                \"Add monitoring/alerts\",\n",
    "                \"Improve error handling\",\n",
    "                \"Update documentation\",\n",
    "                \"Add regression tests\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Display troubleshooting information\n",
    "print(\"üêõ Debugging and Troubleshooting Guide:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show common issues\n",
    "issues = analyze_common_issues()\n",
    "print(\"üîß Common Issues and Solutions:\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "for issue_name, issue_info in issues.items():\n",
    "    print(f\"\\nüö® {issue_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"   üìù Symptoms: {', '.join(issue_info['symptoms'])}\")\n",
    "    print(f\"   üîç Causes: {', '.join(issue_info['causes'])}\")\n",
    "    print(f\"   ‚úÖ Solutions:\")\n",
    "    for solution in issue_info['solutions']:\n",
    "        print(f\"      ‚Ä¢ {solution}\")\n",
    "\n",
    "# Show troubleshooting workflow\n",
    "workflow = create_troubleshooting_workflow()\n",
    "print(f\"\\n\\nüîÑ Systematic Troubleshooting Workflow:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for step_key, step_info in workflow.items():\n",
    "    step_num = step_key.split('_')[1]\n",
    "    print(f\"\\n{step_num}. {step_info['title']}:\")\n",
    "    for action in step_info['actions']:\n",
    "        print(f\"   ‚Ä¢ {action}\")\n",
    "\n",
    "# Create debugging tools\n",
    "def debug_api_endpoint(url: str, timeout: int = 10):\n",
    "    \"\"\"Debug API endpoint connectivity.\"\"\"\n",
    "    \n",
    "    import requests\n",
    "    \n",
    "    debug_info = {\n",
    "        \"url\": url,\n",
    "        \"timestamp\": pd.Timestamp.now(),\n",
    "        \"checks\": {}\n",
    "    }\n",
    "    \n",
    "    # Basic connectivity check\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        debug_info[\"checks\"][\"connectivity\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"status_code\": response.status_code,\n",
    "            \"response_time_ms\": response.elapsed.total_seconds() * 1000\n",
    "        }\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        debug_info[\"checks\"][\"connectivity\"] = {\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": \"Connection refused - service may not be running\"\n",
    "        }\n",
    "    except requests.exceptions.Timeout:\n",
    "        debug_info[\"checks\"][\"connectivity\"] = {\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": \"Timeout - service may be overloaded\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        debug_info[\"checks\"][\"connectivity\"] = {\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "    \n",
    "    return debug_info\n",
    "\n",
    "# Test debugging tool\n",
    "print(f\"\\nüîç Testing API Debugging Tool:\")\n",
    "debug_result = debug_api_endpoint(\"http://localhost:8000/health\")\n",
    "\n",
    "print(f\"üåê URL: {debug_result['url']}\")\n",
    "print(f\"üïí Timestamp: {debug_result['timestamp']}\")\n",
    "\n",
    "for check_name, check_result in debug_result['checks'].items():\n",
    "    status = check_result['status']\n",
    "    emoji = \"‚úÖ\" if status == \"success\" else \"‚ùå\"\n",
    "    print(f\"{emoji} {check_name.title()}: {status.upper()}\")\n",
    "    \n",
    "    if status == \"success\":\n",
    "        if \"status_code\" in check_result:\n",
    "            print(f\"   Status Code: {check_result['status_code']}\")\n",
    "        if \"response_time_ms\" in check_result:\n",
    "            print(f\"   Response Time: {check_result['response_time_ms']:.1f}ms\")\n",
    "    else:\n",
    "        print(f\"   Error: {check_result['error']}\")\n",
    "\n",
    "print(\"\\nüí° Pro Tip: Use this systematic approach to debug issues efficiently!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Automated Testing\n",
    "\n",
    "We can integrate automated tests directly into our notebooks using `pytest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test file\n",
    "test_code = \"\"\"\n",
    "import os\n",
    "\n",
    "def test_project_structure():\n",
    "    # Test that the project structure is as expected\n",
    "    assert os.path.isdir('app'), \\\"'app' directory should exist\\\"\n",
    "    assert os.path.isdir('tests'), \\\"'tests' directory should exist\\\"\n",
    "\n",
    "def test_config_files():\n",
    "    # Test that the main configuration files exist\n",
    "    assert os.path.isfile('config/config.yaml'), \\\"'config.yaml' should exist\\\"\n",
    "\"\"\"\n",
    "with open(\"test_workflow.py\", \"w\") as f:\n",
    "    f.write(test_code)\n",
    "\n",
    "# Run pytest\n",
    "!pytest test_workflow.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Development Workflow Best Practices\n",
    "\n",
    "Let's explore the complete development workflow from idea to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development workflow visualization\n",
    "def create_development_workflow():\n",
    "    \"\"\"Create a comprehensive development workflow guide.\"\"\"\n",
    "    \n",
    "    workflow = {\n",
    "        \"planning\": {\n",
    "            \"title\": \"Planning & Design\",\n",
    "            \"duration\": \"1-2 days\",\n",
    "            \"activities\": [\n",
    "                \"Define requirements and success criteria\",\n",
    "                \"Design API endpoints and data models\",\n",
    "                \"Plan testing strategy and coverage goals\",\n",
    "                \"Create implementation plan and milestones\"\n",
    "            ],\n",
    "            \"deliverables\": [\n",
    "                \"Technical specification document\",\n",
    "                \"API design document\",\n",
    "                \"Test plan\",\n",
    "                \"Project timeline\"\n",
    "            ]\n",
    "        },\n",
    "        \"development\": {\n",
    "            \"title\": \"Local Development\",\n",
    "            \"duration\": \"3-7 days\",\n",
    "            \"activities\": [\n",
    "                \"Set up local development environment\",\n",
    "                \"Implement core functionality\",\n",
    "                \"Write comprehensive unit tests\",\n",
    "                \"Implement logging and error handling\",\n",
    "                \"Create integration tests\",\n",
    "                \"Performance testing and optimization\"\n",
    "            ],\n",
    "            \"tools\": [\n",
    "                \"VS Code / PyCharm\",\n",
    "                \"Docker for local services\",\n",
    "                \"pytest for testing\",\n",
    "                \"black/isort for code formatting\",\n",
    "                \"pre-commit hooks\"\n",
    "            ]\n",
    "        },\n",
    "        \"code_quality\": {\n",
    "            \"title\": \"Code Quality & Review\",\n",
    "            \"duration\": \"1-2 days\",\n",
    "            \"activities\": [\n",
    "                \"Run automated code quality checks\",\n",
    "                \"Achieve target test coverage (>80%)\",\n",
    "                \"Security scanning and vulnerability assessment\",\n",
    "                \"Code review and feedback incorporation\",\n",
    "                \"Documentation updates\"\n",
    "            ],\n",
    "            \"gates\": [\n",
    "                \"All tests passing\",\n",
    "                \"Code quality checks passed\",\n",
    "                \"Security scan clean\",\n",
    "                \"Documentation updated\"\n",
    "            ]\n",
    "        },\n",
    "        \"ci_cd\": {\n",
    "            \"title\": \"CI/CD Pipeline\",\n",
    "            \"duration\": \"1-4 hours\",\n",
    "            \"activities\": [\n",
    "                \"Automated testing on multiple environments\",\n",
    "                \"Code quality validation\",\n",
    "                \"Security scanning\",\n",
    "                \"Container building and deployment\",\n",
    "                \"Integration testing\"\n",
    "            ],\n",
    "            \"benefits\": [\n",
    "                \"Consistent deployment process\",\n",
    "                \"Automated quality gates\",\n",
    "                \"Fast feedback on issues\",\n",
    "                \"Reliable release process\"\n",
    "            ]\n",
    "        },\n",
    "        \"deployment\": {\n",
    "            \"title\": \"Production Deployment\",\n",
    "            \"duration\": \"2-4 hours\",\n",
    "            \"activities\": [\n",
    "                \"Deploy to staging environment\",\n",
    "                \"Integration and end-to-end testing\",\n",
    "                \"Performance validation\",\n",
    "                \"Security assessment\",\n",
    "                \"Production deployment with rollback plan\",\n",
    "                \"Post-deployment monitoring\"\n",
    "            ],\n",
    "            \"environments\": [\n",
    "                \"Development (dev)\",\n",
    "                \"Staging (staging)\",\n",
    "                \"Production (prod)\"\n",
    "            ]\n",
    "        },\n",
    "        \"monitoring\": {\n",
    "            \"title\": \"Monitoring & Maintenance\",\n",
    "            \"duration\": \"Ongoing\",\n",
    "            \"activities\": [\n",
    "                \"Monitor system health and performance\",\n",
    "                \"Track business metrics and KPIs\",\n",
    "                \"Respond to alerts and incidents\",\n",
    "                \"Regular security updates\",\n",
    "                \"Performance optimization\",\n",
    "                \"User feedback collection\"\n",
    "            ],\n",
    "            \"tools\": [\n",
    "                \"Prometheus + Grafana\",\n",
    "                \"ELK stack for logging\",\n",
    "                \"Alertmanager for notifications\",\n",
    "                \"Custom dashboards\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Display development workflow\n",
    "print(\"üöÄ Development Workflow Best Practices:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "workflow = create_development_workflow()\n",
    "\n",
    "for phase_key, phase_info in workflow.items():\n",
    "    print(f\"\\nüìã {phase_info['title']} ({phase_info['duration']})\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if 'activities' in phase_info:\n",
    "        print(\"Activities:\")\n",
    "        for activity in phase_info['activities']:\n",
    "            print(f\"  ‚Ä¢ {activity}\")\n",
    "    \n",
    "    if 'deliverables' in phase_info:\n",
    "        print(\"\\nDeliverables:\")\n",
    "        for deliverable in phase_info['deliverables']:\n",
    "            print(f\"  ‚Ä¢ {deliverable}\")\n",
    "    \n",
    "    if 'tools' in phase_info:\n",
    "        print(\"\\nTools:\")\n",
    "        for tool in phase_info['tools']:\n",
    "            print(f\"  ‚Ä¢ {tool}\")\n",
    "    \n",
    "    if 'gates' in phase_info:\n",
    "        print(\"\\nQuality Gates:\")\n",
    "        for gate in phase_info['gates']:\n",
    "            print(f\"  ‚Ä¢ {gate}\")\n",
    "    \n",
    "    if 'benefits' in phase_info:\n",
    "        print(\"\\nBenefits:\")\n",
    "        for benefit in phase_info['benefits']:\n",
    "            print(f\"  ‚Ä¢ {benefit}\")\n",
    "    \n",
    "    if 'environments' in phase_info:\n",
    "        print(\"\\nEnvironments:\")\n",
    "        for env in phase_info['environments']:\n",
    "            print(f\"  ‚Ä¢ {env}\")\n",
    "\n",
    "# Create workflow timeline visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Workflow phases and estimated durations (in days)\n",
    "phases = list(workflow.keys())\n",
    "durations = [2, 5, 1.5, 0.25, 0.5, 30]  # Rough estimates in days\n",
    "phase_names = [workflow[phase]['title'] for phase in phases]\n",
    "\n",
    "# Create timeline\n",
    "colors = ['lightblue', 'lightgreen', 'orange', 'red', 'purple', 'gray']\n",
    "bars = ax.barh(phases, durations, color=colors, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Duration (days)')\n",
    "ax.set_title('Development Workflow Timeline')\n",
    "ax.set_yticks(range(len(phases)))\n",
    "ax.set_yticklabels(phase_names)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add duration labels\n",
    "for bar, duration in zip(bars, durations):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{duration}d', ha='left', va='center')\n",
    "\n",
    "# Add cumulative timeline\n",
    "cumulative = 0\n",
    "for i, duration in enumerate(durations):\n",
    "    cumulative += duration\n",
    "    ax.axvline(cumulative, color='black', linestyle='--', alpha=0.3)\n",
    "    if i < len(durations) - 1:\n",
    "        ax.text(cumulative + 0.1, len(durations)-1, f'~{cumulative:.1f}d', \n",
    "                ha='left', va='top', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quality metrics summary\n",
    "quality_metrics = {\n",
    "    \"Code Coverage\": \"85%+ (target 90%+)\",\n",
    "    \"Cyclomatic Complexity\": \"< 10 per function\",\n",
    "    \"Technical Debt\": \"< 5% of codebase\",\n",
    "    \"Test Execution Time\": \"< 5 minutes\",\n",
    "    \"Security Vulnerabilities\": \"0 critical/high\",\n",
    "    \"Performance Regression\": \"< 10% degradation\",\n",
    "    \"Mean Time To Recovery\": \"< 1 hour\",\n",
    "    \"Change Failure Rate\": \"< 15%\"\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Quality Metrics Targets:\")\n",
    "print(\"=\" * 40)\n",
    "for metric, target in quality_metrics.items():\n",
    "    print(f\"{metric:<25}: {target}\")\n",
    "\n",
    "print(\"\\nüéØ Development Workflow Complete!\")\n",
    "print(\"\\nüí° Key Takeaways:\")\n",
    "print(\"   ‚Ä¢ Follow systematic development process\")\n",
    "print(\"   ‚Ä¢ Maintain high code quality standards\")\n",
    "print(\"   ‚Ä¢ Implement comprehensive testing\")\n",
    "print(\"   ‚Ä¢ Use CI/CD for automated quality gates\")\n",
    "print(\"   ‚Ä¢ Monitor and iterate on performance\")\n",
    "print(\"   ‚Ä¢ Document everything thoroughly\")\n",
    "print(\"\\nüöÄ Ready to deploy to production? Check the next notebook!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
