{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 KubeSentiment: Getting Started\n",
    "\n",
    "Welcome to **KubeSentiment** - a production-ready sentiment analysis microservice! This notebook will guide you through the basics of using this MLOps sentiment analysis service.\n",
    "\n",
    "## 📋 What is KubeSentiment?\n",
    "\n",
    "KubeSentiment is a comprehensive MLOps solution that provides:\n",
    "- **Real-time sentiment analysis** using DistilBERT\n",
    "- **Production-ready API** built with FastAPI\n",
    "- **Kubernetes deployment** with auto-scaling\n",
    "- **Comprehensive monitoring** with Prometheus & Grafana\n",
    "- **Performance benchmarking** tools\n",
    "- **ONNX optimization** for improved performance\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand the KubeSentiment architecture\n",
    "2. Learn how to interact with the API\n",
    "3. Perform basic sentiment analysis\n",
    "4. Understand the response format\n",
    "5. Explore error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Architecture Overview\n",
    "\n",
    "KubeSentiment follows a microservice architecture:\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[Client] --> B[API Gateway]\n",
    "    B --> C[Sentiment Service]\n",
    "    C --> D[Hugging Face Model]\n",
    "    C --> E[Prediction Cache]\n",
    "    \n",
    "    F[Prometheus] --> G[Metrics]\n",
    "    H[Grafana] --> G\n",
    "    I[AlertManager] --> J[Notifications]\n",
    "```\n",
    "\n",
    "### Key Components:\n",
    "- **FastAPI Backend**: High-performance async API\n",
    "- **DistilBERT Model**: Pre-trained sentiment analysis model\n",
    "- **LRU Cache**: Performance optimization for repeated predictions\n",
    "- **Prometheus Metrics**: Real-time monitoring\n",
    "- **Kubernetes**: Container orchestration and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Setup and Dependencies\n",
    "\n",
    "First, let's install the required dependencies and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for this notebook\n",
    "# Note: This cell might take a few minutes to run\n",
    "!pip install requests httpx pandas matplotlib seaborn plotly\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌐 Connecting to the API\n",
    "\n",
    "KubeSentiment provides a REST API. Let's first check if the service is running and explore the available endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "API_BASE_URL = \"http://localhost:8000\"  # Change this if your service runs on a different port\n",
    "\n",
    "def check_service_health(base_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Check if the sentiment analysis service is healthy.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/health\", timeout=10)\n",
    "        return {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"healthy\": response.status_code == 200,\n",
    "            \"data\": response.json() if response.status_code == 200 else None,\n",
    "            \"error\": None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status_code\": None,\n",
    "            \"healthy\": False,\n",
    "            \"data\": None,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Check service health\n",
    "health_status = check_service_health(API_BASE_URL)\n",
    "\n",
    "if health_status[\"healthy\"]:\n",
    "    print(\"✅ Service is healthy!\")\n",
    "    print(f\"📊 Status: {health_status['data']}\")\n",
    "else:\n",
    "    print(\"❌ Service is not available\")\n",
    "    print(f\"🔍 Error: {health_status['error']}\")\n",
    "    print(\"\\n💡 Make sure the service is running:\")\n",
    "    print(\"   docker run -d -p 8000:8000 sentiment-service:latest\")\n",
    "    print(\"   # or\")\n",
    "    print(\"   python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Model Information\n",
    "\n",
    "Let's explore what model is being used and its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(base_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get information about the loaded model.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/model-info\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Get model information\n",
    "if health_status[\"healthy\"]:\n",
    "    model_info = get_model_info(API_BASE_URL)\n",
    "    \n",
    "    if \"error\" not in model_info:\n",
    "        print(\"🤖 Model Information:\")\n",
    "        print(f\"📝 Model Name: {model_info.get('model_name', 'N/A')}\")\n",
    "        print(f\"✅ Loaded: {model_info.get('is_loaded', False)}\")\n",
    "        print(f\"🚀 Ready: {model_info.get('is_ready', False)}\")\n",
    "        print(f\"💾 Cache Size: {model_info.get('cache_stats', {}).get('cache_size', 0)}\")\n",
    "        print(f\"🔧 PyTorch Version: {model_info.get('torch_version', 'N/A')}\")\n",
    "        print(f\"🖥️ CUDA Available: {model_info.get('cuda_available', False)}\")\n",
    "    else:\n",
    "        print(f\"❌ Error getting model info: {model_info['error']}\")\n",
    "else:\n",
    "    print(\"⏭️ Skipping model info check - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Sentiment Analysis\n",
    "\n",
    "Now let's perform some sentiment analysis! The API accepts text and returns sentiment predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(base_url: str, text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze sentiment of the given text.\"\"\"\n",
    "    try:\n",
    "        payload = {\"text\": text}\n",
    "        response = requests.post(\n",
    "            f\"{base_url}/predict\", \n",
    "            json=payload, \n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\n",
    "                \"error\": f\"HTTP {response.status_code}\", \n",
    "                \"details\": response.text,\n",
    "                \"text\": text\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"text\": text}\n",
    "\n",
    "# Test cases with different sentiments\n",
    "test_texts = [\n",
    "    \"I absolutely love this product! It's amazing and works perfectly.\",\n",
    "    \"This is terrible. I'm very disappointed with the quality.\",\n",
    "    \"The service was okay, nothing special but it worked.\",\n",
    "    \"Outstanding customer support and excellent features!\",\n",
    "    \"Worst experience ever. Complete waste of money.\",\n",
    "    \"It's decent, does what it needs to do without issues.\"\n",
    "]\n",
    "\n",
    "print(\"🎯 Sentiment Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if health_status[\"healthy\"]:\n",
    "    results = []\n",
    "    for text in test_texts:\n",
    "        result = analyze_sentiment(API_BASE_URL, text)\n",
    "        \n",
    "        if \"error\" not in result:\n",
    "            print(f\"📝 Text: {text[:50]}...\")\n",
    "            print(f\"😊 Sentiment: {result['label']}\")\n",
    "            print(f\"📊 Confidence: {result['score']:.3f}\")\n",
    "            print(f\"⚡ Inference Time: {result['inference_time_ms']:.2f}ms\")\n",
    "            print(f\"📏 Text Length: {result['text_length']} chars\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"label\": result[\"label\"],\n",
    "                \"score\": result[\"score\"],\n",
    "                \"inference_time_ms\": result[\"inference_time_ms\"],\n",
    "                \"text_length\": result[\"text_length\"]\n",
    "            })\n",
    "        else:\n",
    "            print(f\"❌ Error analyzing: {text[:30]}...\")\n",
    "            print(f\"   Error: {result['error']}\")\n",
    "            print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"⏭️ Skipping sentiment analysis - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Analyzing Results\n",
    "\n",
    "Let's create some visualizations to understand our sentiment analysis results better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from results\n",
    "if 'results' in locals() and results:\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Display results table\n",
    "    print(\"📊 Sentiment Analysis Summary:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Sentiment Analysis Results', fontsize=16)\n",
    "    \n",
    "    # 1. Sentiment distribution\n",
    "    sentiment_counts = df['label'].value_counts()\n",
    "    axes[0, 0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Sentiment Distribution')\n",
    "    \n",
    "    # 2. Confidence scores\n",
    "    colors = ['green' if label == 'POSITIVE' else 'red' if label == 'NEGATIVE' else 'blue' \n",
    "              for label in df['label']]\n",
    "    axes[0, 1].bar(range(len(df)), df['score'], color=colors)\n",
    "    axes[0, 1].set_title('Confidence Scores')\n",
    "    axes[0, 1].set_xlabel('Sample')\n",
    "    axes[0, 1].set_ylabel('Confidence')\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # 3. Inference time distribution\n",
    "    axes[1, 0].hist(df['inference_time_ms'], bins=10, alpha=0.7, color='skyblue')\n",
    "    axes[1, 0].set_title('Inference Time Distribution')\n",
    "    axes[1, 0].set_xlabel('Time (ms)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 4. Text length vs confidence\n",
    "    scatter_colors = ['green' if label == 'POSITIVE' else 'red' if label == 'NEGATIVE' else 'blue' \n",
    "                      for label in df['label']]\n",
    "    axes[1, 1].scatter(df['text_length'], df['score'], c=scatter_colors, alpha=0.6)\n",
    "    axes[1, 1].set_title('Text Length vs Confidence')\n",
    "    axes[1, 1].set_xlabel('Text Length')\n",
    "    axes[1, 1].set_ylabel('Confidence Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n📈 Summary Statistics:\")\n",
    "    print(f\"📊 Total predictions: {len(df)}\")\n",
    "    print(f\"😊 Positive sentiments: {len(df[df['label'] == 'POSITIVE'])}\")\n",
    "    print(f\"😢 Negative sentiments: {len(df[df['label'] == 'NEGATIVE'])}\")\n",
    "    print(f\"😐 Neutral sentiments: {len(df[df['label'] == 'NEUTRAL'])}\")\n",
    "    print(f\"⚡ Average inference time: {df['inference_time_ms'].mean():.2f}ms\")\n",
    "    print(f\"📏 Average text length: {df['text_length'].mean():.0f} characters\")\n",
    "    print(f\"🎯 Average confidence: {df['score'].mean():.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⏭️ No results to analyze - service not available or no predictions made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚨 Error Handling\n",
    "\n",
    "Let's explore how the API handles various error conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error scenarios\n",
    "error_test_cases = [\n",
    "    {\"text\": \"\", \"description\": \"Empty text\"},\n",
    "    {\"text\": \"   \", \"description\": \"Whitespace only\"},\n",
    "    {\"text\": \"a\" * 10000, \"description\": \"Text too long\"},\n",
    "    {\"text\": \"This is normal text.\", \"description\": \"Valid text (should work)\"}\n",
    "]\n",
    "\n",
    "print(\"🚨 Error Handling Test Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if health_status[\"healthy\"]:\n",
    "    for test_case in error_test_cases:\n",
    "        result = analyze_sentiment(API_BASE_URL, test_case[\"text\"])\n",
    "        \n",
    "        print(f\"🧪 Test: {test_case['description']}\")\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"   ❌ Expected error: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"   ✅ Success: {result['label']} (confidence: {result['score']:.3f})\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"⏭️ Skipping error handling tests - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Performance Metrics\n",
    "\n",
    "Let's check the service's performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(base_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get service performance metrics.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/metrics-json\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Get performance metrics\n",
    "if health_status[\"healthy\"]:\n",
    "    metrics = get_metrics(API_BASE_URL)\n",
    "    \n",
    "    if \"error\" not in metrics:\n",
    "        print(\"📊 Performance Metrics:\")\n",
    "        print(f\"🔧 PyTorch Version: {metrics.get('torch_version', 'N/A')}\")\n",
    "        print(f\"🖥️ CUDA Available: {metrics.get('cuda_available', 'N/A')}\")\n",
    "        print(f\"💾 Memory Allocated: {metrics.get('cuda_memory_allocated_mb', 0)} MB\")\n",
    "        print(f\"📈 Memory Reserved: {metrics.get('cuda_memory_reserved_mb', 0)} MB\")\n",
    "        print(f\"🎮 CUDA Devices: {metrics.get('cuda_device_count', 0)}\")\n",
    "    else:\n",
    "        print(f\"❌ Error getting metrics: {metrics['error']}\")\n",
    "else:\n",
    "    print(\"⏭️ Skipping metrics check - service not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Conclusion\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "\n",
    "1. ✅ **Connected to the KubeSentiment API**\n",
    "2. ✅ **Explored the model capabilities**\n",
    "3. ✅ **Performed sentiment analysis**\n",
    "4. ✅ **Analyzed results with visualizations**\n",
    "5. ✅ **Tested error handling**\n",
    "6. ✅ **Checked performance metrics**\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "Now that you understand the basics, explore these advanced topics:\n",
    "\n",
    "- **[02_model_exploration.ipynb](02_model_exploration.ipynb)**: Deep dive into the sentiment model\n",
    "- **[03_api_testing.ipynb](03_api_testing.ipynb)**: Comprehensive API testing\n",
    "- **[04_benchmarking_analysis.ipynb](04_benchmarking_analysis.ipynb)**: Performance benchmarking\n",
    "- **[05_monitoring_metrics.ipynb](05_monitoring_metrics.ipynb)**: Advanced monitoring\n",
    "- **[06_development_workflow.ipynb](06_development_workflow.ipynb)**: Development workflows\n",
    "- **[07_deployment_guide.ipynb](07_deployment_guide.ipynb)**: Production deployment\n",
    "\n",
    "## 📚 Additional Resources\n",
    "\n",
    "- **[API Documentation](http://localhost:8000/docs)**: Interactive Swagger UI\n",
    "- **[Main README](../README.md)**: Complete project documentation\n",
    "- **[Architecture Guide](../docs/architecture.md)**: System design overview\n",
    "- **[Benchmarking Guide](../docs/BENCHMARKING.md)**: Performance testing\n",
    "\n",
    "---\n",
    "\n",
    "**Happy analyzing! 🎯**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
